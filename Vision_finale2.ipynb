{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5678b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordonnées obstacles noirs : [[(176, 172), (658, 172), (658, -50), (176, -50)], [(942, 418), (1186, 418), (1186, -50), (942, -50)]]\n",
      "Vecteur direction du robot : -87\n",
      "Centroid du robot : [1558  634]\n",
      "Centroid de la goal area : [1296.66666667  882.16666667]\n",
      "Coordonnées obstacles noirs : [[(174, 173), (658, 173), (658, -50), (174, -50)], [(942, 420), (1186, 420), (1186, -50), (942, -50)]]\n",
      "Vecteur direction du robot : 5\n",
      "Centroid du robot : [1495  664]\n",
      "Centroid de la goal area : [799.25 810.5 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-30 13:37:55.677 python[32920:2159077] IMKClient Stall detected, *please Report* your user scenario attaching a spindump (or sysdiagnose) that captures the problem - (imkxpc_bundleIdentifierWithReply:) block performed very slowly (3.09 secs).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordonnées obstacles noirs : [[(174, 173), (658, 173), (658, -50), (174, -50)], [(942, 420), (1186, 420), (1186, -50), (942, -50)]]\n",
      "Vecteur direction du robot : 4\n",
      "Centroid du robot : [1495  665]\n",
      "Centroid de la goal area : [800.25 809.25]\n",
      "Coordonnées obstacles noirs : [[(175, 173), (658, 173), (658, -50), (175, -50)], [(942, 420), (1186, 420), (1186, -50), (942, -50)]]\n",
      "Vecteur direction du robot : 5\n",
      "Centroid du robot : [1495  664]\n",
      "Centroid de la goal area : [800.  806.5]\n",
      "Coordonnées obstacles noirs : [[(175, 173), (658, 173), (658, -50), (175, -50)], [(942, 420), (1186, 420), (1186, -50), (942, -50)]]\n",
      "Vecteur direction du robot : 5\n",
      "Centroid du robot : [1495  664]\n",
      "Centroid de la goal area : [799.   807.75]\n",
      "Coordonnées obstacles noirs : [[(174, 173), (658, 173), (658, -50), (174, -50)], [(942, 420), (1186, 420), (1186, -50), (942, -50)]]\n",
      "Vecteur direction du robot : 6\n",
      "Centroid du robot : [1496  664]\n",
      "Centroid de la goal area : [799.25 804.  ]\n",
      "Coordonnées obstacles noirs : [[(174, 173), (658, 173), (658, -50), (174, -50)], [(942, 420), (1183, 420), (1183, -50), (942, -50)]]\n",
      "Vecteur direction du robot : 1\n",
      "Centroid du robot : [1493  664]\n",
      "Centroid de la goal area : [778.5 653. ]\n",
      "Coordonnées obstacles noirs : [[(175, 173), (658, 173), (658, -50), (175, -50)], [(942, 418), (1184, 418), (1184, -50), (942, -50)]]\n",
      "Vecteur direction du robot : 1\n",
      "Centroid du robot : [1493  664]\n",
      "Centroid de la goal area : [1029.5  709. ]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Definition of the colours thresholds\n",
    "#LOWER_RED = np.array([0, 70, 50])\n",
    "#UPPER_RED = np.array([20, 255, 255])\n",
    "\n",
    "LOWER_RED = np.array([0, 100, 50])\n",
    "UPPER_RED = np.array([15, 255, 255])\n",
    "\n",
    "LOWER_BLUE = np.array([100, 100, 100])\n",
    "UPPER_BLUE = np.array([140, 255, 255])\n",
    "\n",
    "LOWER_GREEN = np.array([40, 40, 40])\n",
    "UPPER_GREEN = np.array([80, 255, 255])\n",
    "\n",
    "LOWER_BLACK = np.array([0, 0, 0])\n",
    "UPPER_BLACK = np.array([179, 255, 30])\n",
    "\n",
    "# Definition of the size of contours considered as noise\n",
    "NOISY_CONTOUR_LENGHT = 1000\n",
    "\n",
    "MARGIN_RED_BLUE_GREEN = 0\n",
    "MARGIN_OBSTACLE = 50\n",
    "\n",
    "\n",
    "def detect_area(image, lower_colour, upper_colour, margin):\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    mask = cv2.inRange(hsv, lower_colour, upper_colour)\n",
    "\n",
    "    blurred_mask = cv2.GaussianBlur(mask, (5, 5), 0)\n",
    "\n",
    "    contours, _ = cv2.findContours(blurred_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    coords = []\n",
    "\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > NOISY_CONTOUR_LENGHT:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            x_with_margin = max(0, x - margin)\n",
    "            y_with_margin = max(0, y - margin)\n",
    "            w_with_margin = min(width, w + 2 * margin)\n",
    "            h_with_margin = min(height, h + 2 * margin)\n",
    "\n",
    "            coords.append([(x_with_margin, height - y_with_margin),\n",
    "                           (x_with_margin + w_with_margin, height - y_with_margin),\n",
    "                           (x_with_margin + w_with_margin, height - y_with_margin - h_with_margin),\n",
    "                           (x_with_margin, height - y_with_margin - h_with_margin)])\n",
    "\n",
    "    return coords\n",
    "\n",
    "\n",
    "def calculate_robot_direction(front_area, back_area):\n",
    "    front_centroid = np.mean(np.array(front_area).reshape(-1, 2), axis=0)\n",
    "    back_centroid = np.mean(np.array(back_area).reshape(-1, 2), axis=0)\n",
    "    direction = (front_centroid - back_centroid).astype(int)\n",
    "    midpoint = ((front_centroid + back_centroid) / 2).astype(int)\n",
    "    return tuple(direction), midpoint\n",
    "\n",
    "\n",
    "def calculate_area_centroid(area_coordinates):\n",
    "    centroid = np.mean(np.array(area_coordinates).reshape(-1, 2), axis=0)\n",
    "    return centroid\n",
    "\n",
    "\n",
    "def draw_annotations(image, obstacles, goal_area, front_robot_area, back_robot_area, robot_centroid, robot_direction):\n",
    "    for coords in obstacles:\n",
    "        cv2.drawContours(image, [np.array(coords)], 0, (128, 0, 128), -1)  # Violet\n",
    "\n",
    "    for coords in goal_area:\n",
    "        cv2.drawContours(image, [np.array(coords)], 0, (255, 0, 0), -1)  # Blue\n",
    "\n",
    "    for coords in front_robot_area + back_robot_area:\n",
    "        cv2.drawContours(image, [np.array(coords)], 0, (0, 0, 255), -1)  # Red\n",
    "\n",
    "    cv2.circle(image, tuple(map(int, robot_centroid)), 5, (0, 255, 0), -1)  # Green\n",
    "\n",
    "    arrow_start = tuple(map(int, robot_centroid))\n",
    "    arrow_end = tuple(map(int, np.add(arrow_start, robot_direction)))\n",
    "    cv2.arrowedLine(image, arrow_start, arrow_end, (0, 255, 255), 2)  # Yellow\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def vision_obstacles_positions():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Erreur: Impossible d'ouvrir la webcam.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if not ret:\n",
    "                print(\"Erreur: Impossible de capturer l'image.\")\n",
    "                break\n",
    "\n",
    "            cv2.imshow('Webcam', frame)\n",
    "\n",
    "            obstacles = detect_area(frame, LOWER_BLACK, UPPER_BLACK, MARGIN_OBSTACLE)\n",
    "            goal_area = detect_area(frame, LOWER_RED, UPPER_RED, MARGIN_RED_BLUE_GREEN)\n",
    "            front_robot_area = detect_area(frame, LOWER_BLUE, UPPER_BLUE, MARGIN_RED_BLUE_GREEN)\n",
    "            back_robot_area = detect_area(frame, LOWER_GREEN, UPPER_GREEN, MARGIN_RED_BLUE_GREEN)\n",
    "\n",
    "            robot_direction, robot_centroid = calculate_robot_direction(front_robot_area, back_robot_area)\n",
    "\n",
    "            goal_centroid = calculate_area_centroid(goal_area)\n",
    "\n",
    "            # Create a copy of the frame for annotations\n",
    "            annotated_frame = frame.copy()\n",
    "\n",
    "            # Draw annotations on the frame\n",
    "            annotated_frame = draw_annotations(annotated_frame, obstacles, goal_area, front_robot_area, back_robot_area,\n",
    "                                               robot_centroid, robot_direction)\n",
    "\n",
    "            # Display the annotated frame\n",
    "            cv2.imshow('Annotated Webcam', annotated_frame)\n",
    "\n",
    "            print(f\"Coordonnées obstacles noirs :\", obstacles)\n",
    "            print(\"Vecteur direction du robot :\", robot_direction[0])\n",
    "            print(\"Centroid du robot :\", robot_centroid)\n",
    "            print(\"Centroid de la goal area :\", goal_centroid)\n",
    "\n",
    "            time.sleep(3)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "# Call the main function\n",
    "vision_obstacles_positions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bdb2f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
