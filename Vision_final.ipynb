{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3a9f807",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zg/x8x9pl755xnbmnyq15zhbpwm0000gn/T/ipykernel_96528/505418250.py:96: RuntimeWarning: invalid value encountered in cast\n",
      "  direction = (front_centroid - back_centroid).astype(int)\n",
      "/var/folders/zg/x8x9pl755xnbmnyq15zhbpwm0000gn/T/ipykernel_96528/505418250.py:99: RuntimeWarning: invalid value encountered in cast\n",
      "  midpoint = ((front_centroid + back_centroid) / 2).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordonnées obstacles noirs : []\n",
      "Vecteur direction du robot : (0, 0)\n",
      "Centroid du robot : [nan nan]\n",
      "Centroid de la goal area : [798.25 481.75]\n",
      "Coordonnées obstacles noirs : [[(0, 1080), (1920, 1080), (1920, 0), (0, 0)]]\n",
      "Vecteur direction du robot : (0, 0)\n",
      "Centroid du robot : [nan nan]\n",
      "Centroid de la goal area : [nan nan]\n",
      "Coordonnées obstacles noirs : [[(3, 1080), (1923, 1080), (1923, 0), (3, 0)]]\n",
      "Vecteur direction du robot : (-465, 206)\n",
      "Centroid du robot : [1226.1  534.3]\n",
      "Centroid de la goal area : [nan nan]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 172\u001b[0m\n\u001b[1;32m    169\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# Appeler la fonction principale\u001b[39;00m\n\u001b[0;32m--> 172\u001b[0m capture_and_display()\n",
      "Cell \u001b[0;32mIn[2], line 160\u001b[0m, in \u001b[0;36mcapture_and_display\u001b[0;34m()\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCentroid de la goal area :\u001b[39m\u001b[38;5;124m\"\u001b[39m, goal_centroid)\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# Attendre 3 secondes (3000 millisecondes)\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# Quitter si la touche 'q' est enfoncée\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Definition of the colours thresholds\n",
    "LOWER_RED = np.array([0, 100, 100])\n",
    "UPPER_RED = np.array([10, 255, 255])\n",
    "\n",
    "LOWER_BLUE = np.array([100, 100, 100])\n",
    "UPPER_BLUE = np.array([140, 255, 255])\n",
    "\n",
    "LOWER_GREEN = np.array([40, 40, 40])\n",
    "UPPER_GREEN = np.array([80, 255, 255])\n",
    "\n",
    "LOWER_BLACK = np.array([0, 0, 0])\n",
    "UPPER_BLACK = np.array([179, 255, 30])\n",
    "\n",
    "# Definition of the size of contours considered as noise\n",
    "NOISY_CONTOUR_LENGHT = 2000\n",
    "\n",
    "MARGIN_RED_BLUE_GREEN = 0  \n",
    "MARGIN_OBSTACLE = 1200\n",
    "\n",
    "def detect_area(image, lower_colour, upper_colour, margin):\n",
    "    '''\n",
    "    @brief   Detects areas corresponding to a color and returns the coordinates of the vertices of these areas.\n",
    "\n",
    "    @param   image        -> Image array (numpy array) captured from the camera\n",
    "             lower_colour -> LOWER_RED, LOWER_BLACK, LOWER_BLUE, LOWER_GREEN\n",
    "             upper_colour -> UPPER_RED, UPPER_BLACK, UPPER_BLUE, UPPER_GREEN\n",
    "             margin       -> MARGIN_OBSTACLE, MARGIN_RED_BLUE_GREEN\n",
    "\n",
    "    @return  coords       -> list of the coordinates of the vertices for each area\n",
    "    '''\n",
    "\n",
    "    height, width, _ = image.shape  # Give the size of the image\n",
    "\n",
    "    # Converts the image in the HSV space\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Filter the image to retain only pixels of the desired color\n",
    "    mask = cv2.inRange(hsv, lower_colour, upper_colour)\n",
    "\n",
    "    # Blur masks to reduce noise\n",
    "    blurred_mask = cv2.GaussianBlur(mask, (5, 5), 0)\n",
    "\n",
    "    # Find contours in the filtered mask\n",
    "    contours, _ = cv2.findContours(blurred_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # List to store coordinates of detected zones\n",
    "    coords = []\n",
    "\n",
    "    # Browse all contours found\n",
    "    for contour in contours:\n",
    "        \n",
    "        # Ignore small contours that could be noise\n",
    "        if cv2.contourArea(contour) > NOISY_CONTOUR_LENGHT:\n",
    "            \n",
    "            # Get the coordinates of the rectangle enclosing the area\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            \n",
    "            # Add the coordinates of the zone's vertices with a change of reference point (bottom left corner)\n",
    "            # Ajoutez la marge de 300 pixels\n",
    "            x_with_margin = max(0, x - margin)\n",
    "            y_with_margin = max(0, y - margin)\n",
    "            w_with_margin = min(width, w + 2 * margin)\n",
    "            h_with_margin = min(height, h + 2 * margin)\n",
    "\n",
    "            coords.append([(x_with_margin, height - y_with_margin),\n",
    "                           (x_with_margin + w_with_margin, height - y_with_margin),\n",
    "                           (x_with_margin + w_with_margin, height - y_with_margin - h_with_margin),\n",
    "                           (x_with_margin, height - y_with_margin - h_with_margin)])\n",
    "\n",
    "    return coords\n",
    "\n",
    "\n",
    "def calculate_robot_direction(front_area, back_area):\n",
    "    '''\n",
    "    @brief   Calculates the direction vector of the robot.\n",
    " \n",
    "    @param   front_area   -> List of coordinates for the front area (blue)\n",
    "             back_area    -> List of coordinates for the back area (green)\n",
    "    \n",
    "    @return  direction    -> tuple represents the direction vector coordinates\n",
    "                             list represents the midpoint coordinates\n",
    "    '''\n",
    "    \n",
    "    # Calculate the centroid of the front area (blue)\n",
    "    front_centroid = np.mean(np.array(front_area).reshape(-1, 2), axis=0)\n",
    "    \n",
    "    # Calculate the centroid of the back area (green)\n",
    "    back_centroid = np.mean(np.array(back_area).reshape(-1, 2), axis=0)\n",
    "    \n",
    "    # Calculate the direction vector of the robot\n",
    "    direction = (front_centroid - back_centroid).astype(int)\n",
    "    \n",
    "    # Calculate the midpoint between the centroids\n",
    "    midpoint = ((front_centroid + back_centroid) / 2).astype(int)\n",
    "    \n",
    "    return tuple(direction), midpoint\n",
    "\n",
    "\n",
    "\n",
    "def calculate_area_centroid(area_coordinates):\n",
    "    '''\n",
    "    @brief   Calculates the centroid coordinates of an area.\n",
    " \n",
    "    @param   area_coordinates -> List of coordinates area\n",
    "    \n",
    "    @return  centroid         -> List that represents the centroid coordinates\n",
    "    '''\n",
    "    \n",
    "    # Calculate the centroid of the area\n",
    "    centroid = np.mean(np.array(area_coordinates).reshape(-1, 2), axis=0)\n",
    "    \n",
    "    return centroid\n",
    "def capture_and_display():\n",
    "    # Ouvrir la webcam (index 0 par défaut)\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Vérifier si la webcam est ouverte correctement\n",
    "    if not cap.isOpened():\n",
    "        print(\"Erreur: Impossible d'ouvrir la webcam.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            # Capturer une image depuis la webcam\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if not ret:\n",
    "                print(\"Erreur: Impossible de capturer l'image.\")\n",
    "                break\n",
    "\n",
    "            # Afficher l'image\n",
    "            cv2.imshow('Webcam', frame)\n",
    "\n",
    "            # Find the contours of each areas\n",
    "            obstacles = detect_area(frame, LOWER_BLACK, UPPER_BLACK, MARGIN_OBSTACLE)\n",
    "            goal_area = detect_area(frame, LOWER_RED, UPPER_RED, MARGIN_RED_BLUE_GREEN)\n",
    "            front_robot_area = detect_area(frame, LOWER_BLUE, UPPER_BLUE, MARGIN_RED_BLUE_GREEN)\n",
    "            back_robot_area = detect_area(frame, LOWER_GREEN, UPPER_GREEN, MARGIN_RED_BLUE_GREEN)\n",
    "\n",
    "            # Find the robot direction vector and its midpoint\n",
    "            robot_direction = calculate_robot_direction(front_robot_area, back_robot_area)\n",
    "            robot_centroid = calculate_area_centroid(back_robot_area)\n",
    "\n",
    "            # Find the centroid of the goal area\n",
    "            goal_centroid = calculate_area_centroid(goal_area)\n",
    "            \n",
    "\n",
    "            # Afficher les coordonnées détectées (vous pouvez les utiliser comme nécessaire)\n",
    "            print(f\"Coordonnées obstacles noirs :\", obstacles)\n",
    "            print(\"Vecteur direction du robot :\", robot_direction[0])\n",
    "            print(\"Centroid du robot :\", robot_centroid)\n",
    "            print(\"Centroid de la goal area :\", goal_centroid)\n",
    "\n",
    "            # Attendre 3 secondes (3000 millisecondes)\n",
    "            time.sleep(3)\n",
    "\n",
    "            # Quitter si la touche 'q' est enfoncée\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    finally:\n",
    "        # Libérer la webcam et fermer la fenêtre\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "# Appeler la fonction principale\n",
    "capture_and_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7d99aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
