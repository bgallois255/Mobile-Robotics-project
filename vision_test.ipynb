{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rapha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\rapha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordonnées obstacles noirs : []\n",
      "Centroid de la goal area : [nan nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rapha\\AppData\\Local\\Temp\\ipykernel_10756\\533970265.py:66: RuntimeWarning: invalid value encountered in cast\n",
      "  direction = (front_centroid - back_centroid).astype(int)\n",
      "C:\\Users\\rapha\\AppData\\Local\\Temp\\ipykernel_10756\\533970265.py:67: RuntimeWarning: invalid value encountered in cast\n",
      "  midpoint = ((front_centroid + back_centroid) / 2).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vecteur direction du robot : -2147483648\n",
      "Centroid du robot : [-2147483648 -2147483648]\n",
      "Vecteur direction du robot : -2147483648\n",
      "Centroid du robot : [-2147483648 -2147483648]\n",
      "Vecteur direction du robot : -2147483648\n",
      "Centroid du robot : [-2147483648 -2147483648]\n",
      "Vecteur direction du robot : -2147483648\n",
      "Centroid du robot : [-2147483648 -2147483648]\n",
      "Vecteur direction du robot : -2147483648\n",
      "Centroid du robot : [-2147483648 -2147483648]\n",
      "Vecteur direction du robot : -2147483648\n",
      "Centroid du robot : [-2147483648 -2147483648]\n",
      "Vecteur direction du robot : -2147483648\n",
      "Centroid du robot : [-2147483648 -2147483648]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rapha\\OneDrive\\Bureau\\EPFL RO MA1\\Robotique Mobile\\Mobile-Robotics-project\\vision_test.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/rapha/OneDrive/Bureau/EPFL%20RO%20MA1/Robotique%20Mobile/Mobile-Robotics-project/vision_test.ipynb#W0sZmlsZQ%3D%3D?line=128'>129</a>\u001b[0m obst, goal \u001b[39m=\u001b[39m vision_obstacles_and_goal()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/rapha/OneDrive/Bureau/EPFL%20RO%20MA1/Robotique%20Mobile/Mobile-Robotics-project/vision_test.ipynb#W0sZmlsZQ%3D%3D?line=130'>131</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/rapha/OneDrive/Bureau/EPFL%20RO%20MA1/Robotique%20Mobile/Mobile-Robotics-project/vision_test.ipynb#W0sZmlsZQ%3D%3D?line=131'>132</a>\u001b[0m     robot \u001b[39m=\u001b[39m vision_robot()\n",
      "\u001b[1;32mc:\\Users\\rapha\\OneDrive\\Bureau\\EPFL RO MA1\\Robotique Mobile\\Mobile-Robotics-project\\vision_test.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/rapha/OneDrive/Bureau/EPFL%20RO%20MA1/Robotique%20Mobile/Mobile-Robotics-project/vision_test.ipynb#W0sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvision_robot\u001b[39m():\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/rapha/OneDrive/Bureau/EPFL%20RO%20MA1/Robotique%20Mobile/Mobile-Robotics-project/vision_test.ipynb#W0sZmlsZQ%3D%3D?line=103'>104</a>\u001b[0m     cap \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mVideoCapture(\u001b[39m0\u001b[39;49m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/rapha/OneDrive/Bureau/EPFL%20RO%20MA1/Robotique%20Mobile/Mobile-Robotics-project/vision_test.ipynb#W0sZmlsZQ%3D%3D?line=105'>106</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m cap\u001b[39m.\u001b[39misOpened():\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/rapha/OneDrive/Bureau/EPFL%20RO%20MA1/Robotique%20Mobile/Mobile-Robotics-project/vision_test.ipynb#W0sZmlsZQ%3D%3D?line=106'>107</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mErreur: Impossible d\u001b[39m\u001b[39m'\u001b[39m\u001b[39mouvrir la webcam.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "vision.py\n",
    "vision\n",
    "Authors: Benoît Gallois, Jehan Corcelle, Arto Dubuisson, Raphaël Dousson\n",
    "'''\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Definition of the colours thresholds\n",
    "#LOWER_RED = np.array([0, 70, 50])\n",
    "#UPPER_RED = np.array([20, 255, 255])\n",
    "\n",
    "LOWER_RED = np.array([0, 100, 50])\n",
    "UPPER_RED = np.array([15, 255, 255])\n",
    "\n",
    "LOWER_BLUE = np.array([100, 100, 100])\n",
    "UPPER_BLUE = np.array([140, 255, 255])\n",
    "\n",
    "LOWER_GREEN = np.array([40, 40, 40])\n",
    "UPPER_GREEN = np.array([80, 255, 255])\n",
    "\n",
    "LOWER_BLACK = np.array([0, 0, 0])\n",
    "UPPER_BLACK = np.array([179, 255, 30])\n",
    "\n",
    "# Definition of the size of contours considered as noise\n",
    "NOISY_CONTOUR_LENGHT = 1000\n",
    "\n",
    "MARGIN_RED_BLUE_GREEN = 0\n",
    "MARGIN_OBSTACLE = 50\n",
    "\n",
    "\n",
    "def detect_area(image, lower_colour, upper_colour, margin):\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    mask = cv2.inRange(hsv, lower_colour, upper_colour)\n",
    "\n",
    "    blurred_mask = cv2.GaussianBlur(mask, (5, 5), 0)\n",
    "\n",
    "    contours, _ = cv2.findContours(blurred_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    coords = []\n",
    "\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > NOISY_CONTOUR_LENGHT:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            x_with_margin = max(0, x - margin)\n",
    "            y_with_margin = max(0, y - margin)\n",
    "            w_with_margin = min(width, w + 2 * margin)\n",
    "            h_with_margin = min(height, h + 2 * margin)\n",
    "\n",
    "            coords.append([(x_with_margin, height - y_with_margin),\n",
    "                           (x_with_margin + w_with_margin, height - y_with_margin),\n",
    "                           (x_with_margin + w_with_margin, height - y_with_margin - h_with_margin),\n",
    "                           (x_with_margin, height - y_with_margin - h_with_margin)])\n",
    "\n",
    "    return coords\n",
    "\n",
    "\n",
    "def calculate_robot_direction(front_area, back_area):\n",
    "    front_centroid = np.mean(np.array(front_area).reshape(-1, 2), axis=0)\n",
    "    back_centroid = np.mean(np.array(back_area).reshape(-1, 2), axis=0)\n",
    "    direction = (front_centroid - back_centroid).astype(int)\n",
    "    midpoint = ((front_centroid + back_centroid) / 2).astype(int)\n",
    "    return tuple(direction), midpoint\n",
    "\n",
    "\n",
    "def calculate_area_centroid(area_coordinates):\n",
    "    centroid = np.mean(np.array(area_coordinates).reshape(-1, 2), axis=0)\n",
    "    return centroid\n",
    "\n",
    "\n",
    "def vision_obstacles_and_goal():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Erreur: Impossible d'ouvrir la webcam.\")\n",
    "        return\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    time.sleep(2)\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"Erreur: Impossible de capturer l'image.\")\n",
    "        return\n",
    "\n",
    "    cv2.imshow('Webcam', frame)\n",
    "\n",
    "    obstacles = detect_area(frame, LOWER_BLACK, UPPER_BLACK, MARGIN_OBSTACLE)\n",
    "    goal_area = detect_area(frame, LOWER_RED, UPPER_RED, MARGIN_RED_BLUE_GREEN)\n",
    "   \n",
    "    goal_centroid = calculate_area_centroid(goal_area)\n",
    "\n",
    "    print(f\"Coordonnées obstacles noirs :\", obstacles)\n",
    "    print(\"Centroid de la goal area :\", goal_centroid)\n",
    "    \n",
    "    return obstacles, goal_centroid\n",
    "\n",
    "def vision_robot():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Erreur: Impossible d'ouvrir la webcam.\")\n",
    "        return\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"Erreur: Impossible de capturer l'image.\")\n",
    "        return\n",
    "\n",
    "    cv2.imshow('Webcam', frame)\n",
    "\n",
    "    front_robot_area = detect_area(frame, LOWER_BLUE, UPPER_BLUE, MARGIN_RED_BLUE_GREEN)\n",
    "    back_robot_area = detect_area(frame, LOWER_GREEN, UPPER_GREEN, MARGIN_RED_BLUE_GREEN)\n",
    "\n",
    "    robot_direction, robot_centroid = calculate_robot_direction(front_robot_area, back_robot_area)\n",
    "\n",
    "    print(\"Vecteur direction du robot :\", robot_direction[0])\n",
    "    print(\"Centroid du robot :\", robot_centroid)\n",
    "    \n",
    "    return robot_centroid, robot_direction\n",
    "\n",
    "\n",
    "obst, goal = vision_obstacles_and_goal()\n",
    "\n",
    "while True:\n",
    "    robot = vision_robot()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
